{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con una serie pequeña de datos proporcionados por la maestra. Nuestro objetivo es que de un connjunto de datos obtengamos una linealización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood - Método metrópolis\n",
    "\n",
    "Usando los mismos datos anteriores ahora intentaremos encontrar la recta más acercada con el método de metrópolis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estadística, la función de verosimilitud (o, simplemente, verosimilitud) es una función de los parámetros de un modelo estadístico que permite realizar inferencias acerca de su valor a partir de un conjunto de observaciones.\n",
    "\n",
    "En cierto sentido, la verosimilitud es una versión inversa de la probabilidad condicional. Conocido un parámetro B, la probabilidad condicional de A es P(A|B), pero si se conoce A, pueden realizarse inferencias sobre el valor de B gracias al teorema de Bayes, según el cual\n",
    "\n",
    "$ {\\displaystyle P(B\\mid A)={\\frac {P(A\\mid B)\\;P(B)}{P(A)}}.\\!}$\n",
    "\n",
    "La función de verosimilitud, $L( b |A)$, definida como\n",
    "\n",
    "${\\displaystyle L(b\\mid A)=P(A\\mid B=b),\\!}$\n",
    "\n",
    " Pero cuando la noción de verosimilitud se extiende a variables aleatorias con una función de densidad f sobre, por ejemplo, el eje real, la probabilidad de un evento cualquiera es nula. Por ejemplo, supóngase el caso de tener una variable aleatoria real de distribución desconocida X de la que se extrae una muestra ${\\displaystyle x_{1},...,x_{n}}$ de observaciones independientes. Supóngase también que se dispone de una familia parametrizada de funciones de densidad ${\\displaystyle f_{\\theta }(x)}$ (es decir, que existe una función de densidad ${\\displaystyle f_{\\theta }(x)}$ para cada valor del parámetro$ {\\displaystyle \\theta (x)}$.\n",
    "\n",
    "En este caso, ${\\displaystyle \\theta (x)}$ juega el papel de parámetro desconocido y es razonable definir la función de verosimilitud ${\\displaystyle L(\\theta )}$ de la siguiente manera:\n",
    "\n",
    "${\\displaystyle L(\\theta )=L(\\theta \\mid x_{1},...,x_{n})=\\prod _{i}f_{\\theta }(x_{i}).}{\\displaystyle L(\\theta )=L(\\theta \\mid x_{1},...,x_{n})=\\prod _{i}f_{\\theta }(x_{i}).}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos proporcionados por la maestra, son 3 columnas, x, y, error de y\n",
    "#La columna \"error de y\" nos servirá para la distribución chi^2\n",
    "\n",
    "data = np.load('fit_exercise.npy') \n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[0,:]      #primer renglón\n",
    "#print(x)\n",
    "y = data[1,:]      #segundo renglón\n",
    "y_err = data[2,:]  #tercer renglón\n",
    "n = len(x)         #Tamaño de  nuestros vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Primero vamos a definir una función de una recta.\n",
    "Nuestro propósito principal es encontrar los coeficientes m y b correctos tales que se ajustan a la solución obtenida en el\n",
    "ejercicio pasado.\n",
    "Vamos a conocer todos los m y b posibles que se acerquen a la solución ideal.\"\"\"\n",
    "\n",
    "n_pasos = 30000               #número de iteraciones que vamos a realizar nuestro experimento, mientras más grande más probable es que encontremos los m y b correctos\n",
    "m = np.zeros(n_pasos)        #Aquí vamosa guardar todos los m que encontremos se acercan a la recta ideal\n",
    "b = np.zeros(n_pasos)        #Aquí vamosa guardar todos los b que encontremos que se acercan a la recta ideal\n",
    "\n",
    "m[0] = 1      #aquí YO fijo ARBITRARIAMENTE que este valor de 'm' puede ser el correcto, aquí comienza a contar mi programa.\n",
    "b[0] = 1      #aquí YO fijo ARBITRARIAMENTE que este valor de 'b' puede ser el correcto, aquí comienza a contar mi programa.\n",
    "\n",
    "#es preferible no comenzar en cero, para poder visualizar nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo de metrópolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos la función con la que aproximaremos nuestro likelihood, en este caso es una func. lineal\n",
    "def f(x,pendiente,cte):\n",
    "    f = pendiente*x + cte\n",
    "    return f\n",
    "\n",
    "#definimos una función para el likelihood\n",
    "def Likelihood(m,b,y,x,error_y):\n",
    "    #y es los valores reales que tiene nuestra distribución en el i-ésimo evento\n",
    "    #f es la función de distribución a la que deseamos acercarnos\n",
    "    L=1\n",
    "    for i in range(len(y)):\n",
    "        L = L*((y[i] - f(x[i],m,b)))/error_y[i]\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de iteraciones: 14836\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Aquí vamos a comenzar a hacer iteraciones de los valores de m y de b para encontrar el que se acerque más a la línea ideal.\n",
    "Para esto comenzaremos en los 'm' y 'b' que fijamos anteriormente y le añadiremos un valor ALEATORIO hacia el cual\n",
    "se pueda mover de manera que se acerque a la solución más acertada\"\"\"\n",
    "\n",
    "delta = 1\n",
    "L_v = 1\n",
    "m_v = 1\n",
    "b_v = 1\n",
    "counting = 0\n",
    "for i in range(1,n_pasos):\n",
    "    m_rnd = (np.random.rand(1) -0.5)*delta  #m aleatorios\n",
    "    b_rnd = (np.random.rand(1) - 0.5)*delta #b aleatorios\n",
    "    #el 0.5 es para que también nos den número negativos\n",
    "    \n",
    "    m_n = m_v + m_rnd  #aquí guardamos moentáneamente 'm'\n",
    "    b_n = b_v + b_rnd #aquí guardamos moentáneamente 'b'\n",
    "    \n",
    "    L_n = Likelihood(m_n,b_n,x,y,y_err)\n",
    "    #print(L_n)\n",
    "    \n",
    "    if L_n > L_v: #comparamos si el likelihood nuevo es mayor al viejo\n",
    "        \n",
    "        \"\"\"Reescribimos los valores de nuestras constantes\"\"\"\n",
    "        \n",
    "        L_v = np.copy(L_n)\n",
    "        m_v = np.copy(m_n)\n",
    "        b_v = np.copy(b_n)\n",
    "        \n",
    "        counting = counting+1\n",
    "        \n",
    "        plt.plot(m_n,b_n,'o')\n",
    "        plt.xlabel('m')\n",
    "        plt.ylabel('b')\n",
    "        \n",
    "        #print('m = ',m_n)\n",
    "        #print('b = ',b_n)    \n",
    "    \n",
    "print('número de iteraciones:',counting)    \n",
    "\n",
    "#print(L_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
